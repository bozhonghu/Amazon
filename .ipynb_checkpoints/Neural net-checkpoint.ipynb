{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Seed the random number generator:\n",
    "np.random.seed(1)\n",
    "\n",
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_data('training_data.txt')\n",
    "y = X[:, 0]\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1000)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(X_train, y_train, X_test, y_test):\n",
    "    ## Create your own model here given the constraints in the problem\n",
    "    model = Sequential() # Use np.reshape instead of this in hw\n",
    "    model.add(Dense(1000, input_dim = 1000))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(500))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(200))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    ## Printing a summary of the layers and weights in your model\n",
    "    #model.summary()\n",
    "    \n",
    "    ## In the line below we have specified the loss function as 'mse' (Mean Squared Error) because in the above code we did not one-hot encode the labels.\n",
    "    ## In your implementation, since you are one-hot encoding the labels, you should use 'categorical_crossentropy' as your loss.\n",
    "    ## You will likely have the best results with RMS prop or Adam as your optimizer.  In the line below we use Adadelta\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])\n",
    "    \n",
    "    fit = model.fit(X_train, y_train, batch_size=128, epochs=2,\n",
    "        verbose=1)\n",
    "\n",
    "    ## Printing the accuracy of our model, according to the loss function specified in model.compile above\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return score[1], model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18000/18000 [==============================] - 11s 625us/step - loss: 0.4519 - acc: 0.7902\n",
      "Epoch 2/2\n",
      "18000/18000 [==============================] - 10s 565us/step - loss: 0.3130 - acc: 0.8652\n",
      "Test score: 0.3424795902967453\n",
      "Test accuracy: 0.852\n",
      "Epoch 1/2\n",
      "18000/18000 [==============================] - 11s 617us/step - loss: 0.4533 - acc: 0.7878\n",
      "Epoch 2/2\n",
      "18000/18000 [==============================] - 11s 639us/step - loss: 0.3055 - acc: 0.8695\n",
      "Test score: 0.3306661276817322\n",
      "Test accuracy: 0.8515\n",
      "Epoch 1/2\n",
      "18000/18000 [==============================] - 12s 667us/step - loss: 0.4489 - acc: 0.7926\n",
      "Epoch 2/2\n",
      "18000/18000 [==============================] - 11s 606us/step - loss: 0.3022 - acc: 0.8688\n",
      "Test score: 0.3663601670265198\n",
      "Test accuracy: 0.853\n",
      "Epoch 1/2\n",
      "18000/18000 [==============================] - 11s 630us/step - loss: 0.4461 - acc: 0.7886\n",
      "Epoch 2/2\n",
      "18000/18000 [==============================] - 10s 566us/step - loss: 0.3091 - acc: 0.8662\n",
      "Test score: 0.33210494375228883\n",
      "Test accuracy: 0.8515\n",
      "Epoch 1/2\n",
      "18000/18000 [==============================] - 11s 637us/step - loss: 0.4421 - acc: 0.7942\n",
      "Epoch 2/2\n",
      "18000/18000 [==============================] - 10s 572us/step - loss: 0.3018 - acc: 0.8702\n",
      "Test score: 0.34632509303092956\n",
      "Test accuracy: 0.8485\n",
      "Epoch 1/2\n",
      "18000/18000 [==============================] - 12s 644us/step - loss: 0.4524 - acc: 0.7890\n",
      "Epoch 2/2\n",
      "18000/18000 [==============================] - 10s 575us/step - loss: 0.3039 - acc: 0.8706\n",
      "Test score: 0.3564727427959442\n",
      "Test accuracy: 0.846\n",
      "Epoch 1/2\n",
      "18000/18000 [==============================] - 12s 666us/step - loss: 0.4504 - acc: 0.7867\n",
      "Epoch 2/2\n",
      "18000/18000 [==============================] - 11s 586us/step - loss: 0.3062 - acc: 0.8683\n",
      "Test score: 0.3527608847618103\n",
      "Test accuracy: 0.85\n",
      "Epoch 1/2\n",
      "18000/18000 [==============================] - 13s 735us/step - loss: 0.4479 - acc: 0.7908\n",
      "Epoch 2/2\n",
      "18000/18000 [==============================] - 12s 674us/step - loss: 0.3070 - acc: 0.8685\n",
      "Test score: 0.36358436560630797\n",
      "Test accuracy: 0.8385\n",
      "Epoch 1/2\n",
      "18000/18000 [==============================] - 13s 744us/step - loss: 0.4548 - acc: 0.7849\n",
      "Epoch 2/2\n",
      "18000/18000 [==============================] - 12s 644us/step - loss: 0.3081 - acc: 0.8661\n",
      "Test score: 0.3410640499591827\n",
      "Test accuracy: 0.853\n",
      "Epoch 1/2\n",
      "18000/18000 [==============================] - 15s 838us/step - loss: 0.4624 - acc: 0.7886\n",
      "Epoch 2/2\n",
      "18000/18000 [==============================] - 11s 586us/step - loss: 0.3088 - acc: 0.8656\n",
      "Test score: 0.34036805033683776\n",
      "Test accuracy: 0.843\n",
      "0.8487\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "\n",
    "    scores.append(make_model(X_train, y_train, X_test, y_test)[0])\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^ mean score: 0.8487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 15s 751us/step - loss: 0.4320 - acc: 0.7960\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 8s 392us/step - loss: 0.3076 - acc: 0.8688\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 8s 391us/step - loss: 0.2423 - acc: 0.8981\n",
      "Test score: 0.130459776002\n",
      "Test accuracy: 0.96495\n"
     ]
    }
   ],
   "source": [
    "X_test = load_data('test_data.txt')\n",
    "X = load_data('training_data.txt')\n",
    "y = X[:, 0]\n",
    "y = to_categorical(y)\n",
    "X = X[:, 1:]\n",
    "m = make_model(X, y, X, y)[1]\n",
    "pred = m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_pred(pred):\n",
    "    result = [1 if i[0] == 0 else 0 for i in np.round(pred)]\n",
    "    with open(\"result.txt\", \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\") \n",
    "        for i in range(1, len(result) + 1):\n",
    "            f.write(str(i) + \",\" + str(result[i-1]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_pred(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

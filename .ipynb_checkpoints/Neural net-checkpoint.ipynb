{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Seed the random number generator:\n",
    "np.random.seed(1)\n",
    "\n",
    "def load_data(filename, skiprows = 1):\n",
    "    \"\"\"\n",
    "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
    "    \n",
    "    Inputs:\n",
    "        filename: given as a string.\n",
    "        \n",
    "    Outputs:\n",
    "        Data contained in the file, returned as a numpy ndarray\n",
    "    \"\"\"\n",
    "    return np.loadtxt(filename, skiprows=skiprows, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_data('training_data.txt')\n",
    "y = X[:15000, 0]\n",
    "X = X[:15000, 1:]\n",
    "\n",
    "\n",
    "#X_test = load_data('test_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(sum(y[:,0]))\n",
    "print(sum(y[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(X_train, y_train, X_test, y_test):\n",
    "    ## Create your own model here given the constraints in the problem\n",
    "    model = Sequential() # Use np.reshape instead of this in hw\n",
    "    model.add(Dense(1000, input_dim = 1000))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(500))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(200))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    ## Printing a summary of the layers and weights in your model\n",
    "    # model.summary()\n",
    "    \n",
    "    ## In the line below we have specified the loss function as 'mse' (Mean Squared Error) because in the above code we did not one-hot encode the labels.\n",
    "    ## In your implementation, since you are one-hot encoding the labels, you should use 'categorical_crossentropy' as your loss.\n",
    "    ## You will likely have the best results with RMS prop or Adam as your optimizer.  In the line below we use Adadelta\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])\n",
    "    \n",
    "    fit = model.fit(X_train, y_train, batch_size=128, epochs=2,\n",
    "        verbose=1)\n",
    "\n",
    "    ## Printing the accuracy of our model, according to the loss function specified in model.compile above\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return score[1], model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "13500/13500 [==============================] - 8s 569us/step - loss: 0.4782 - acc: 0.7728\n",
      "Epoch 2/2\n",
      "13500/13500 [==============================] - 4s 281us/step - loss: 0.3149 - acc: 0.8658\n",
      "Test score: 0.354118350585\n",
      "Test accuracy: 0.849333333492\n",
      "Epoch 1/2\n",
      "13500/13500 [==============================] - 7s 533us/step - loss: 0.4837 - acc: 0.7670\n",
      "Epoch 2/2\n",
      "13500/13500 [==============================] - 4s 305us/step - loss: 0.3069 - acc: 0.8699\n",
      "Test score: 0.364415814996\n",
      "Test accuracy: 0.844666666985\n",
      "Epoch 1/2\n",
      "13500/13500 [==============================] - 8s 597us/step - loss: 0.4747 - acc: 0.7761\n",
      "Epoch 2/2\n",
      "13500/13500 [==============================] - 4s 326us/step - loss: 0.3141 - acc: 0.8657\n",
      "Test score: 0.374452368577\n",
      "Test accuracy: 0.841333332856\n",
      "Epoch 1/2\n",
      "13500/13500 [==============================] - 8s 614us/step - loss: 0.4770 - acc: 0.7743\n",
      "Epoch 2/2\n",
      "13500/13500 [==============================] - 4s 294us/step - loss: 0.3050 - acc: 0.8686\n",
      "Test score: 0.375376793424\n",
      "Test accuracy: 0.825333333651\n",
      "Epoch 1/2\n",
      "13500/13500 [==============================] - 8s 601us/step - loss: 0.4781 - acc: 0.7766\n",
      "Epoch 2/2\n",
      "13500/13500 [==============================] - 4s 291us/step - loss: 0.3057 - acc: 0.8687\n",
      "Test score: 0.363531219323\n",
      "Test accuracy: 0.848000000477\n",
      "Epoch 1/2\n",
      "13500/13500 [==============================] - 8s 576us/step - loss: 0.4777 - acc: 0.7763\n",
      "Epoch 2/2\n",
      "13500/13500 [==============================] - 4s 287us/step - loss: 0.3022 - acc: 0.8684\n",
      "Test score: 0.357704377572\n",
      "Test accuracy: 0.861999999841\n",
      "Epoch 1/2\n",
      "13500/13500 [==============================] - 9s 644us/step - loss: 0.4732 - acc: 0.7767\n",
      "Epoch 2/2\n",
      "13500/13500 [==============================] - 4s 331us/step - loss: 0.3061 - acc: 0.8707\n",
      "Test score: 0.375968079964\n",
      "Test accuracy: 0.838666666826\n",
      "Epoch 1/2\n",
      "13500/13500 [==============================] - 8s 608us/step - loss: 0.4794 - acc: 0.7763\n",
      "Epoch 2/2\n",
      "13500/13500 [==============================] - 4s 297us/step - loss: 0.3105 - acc: 0.8629\n",
      "Test score: 0.384275251547\n",
      "Test accuracy: 0.843333333174\n",
      "Epoch 1/2\n",
      "13500/13500 [==============================] - 8s 578us/step - loss: 0.4726 - acc: 0.7758\n",
      "Epoch 2/2\n",
      "13500/13500 [==============================] - 4s 285us/step - loss: 0.3092 - acc: 0.8650\n",
      "Test score: 0.373132953803\n",
      "Test accuracy: 0.85133333381\n",
      "Epoch 1/2\n",
      "13500/13500 [==============================] - 8s 584us/step - loss: 0.4742 - acc: 0.7746\n",
      "Epoch 2/2\n",
      "13500/13500 [==============================] - 4s 297us/step - loss: 0.3024 - acc: 0.8732\n",
      "Test score: 0.40353085343\n",
      "Test accuracy: 0.808000000477\n",
      "0.841200000159\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "\n",
    "    scores.append(make_model(X_train, y_train, X_test, y_test)[0])\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_data('training_data.txt')\n",
    "y = X[:, 0]\n",
    "X = X[:, 1:]\n",
    "\n",
    "X_test = load_data('test_data.txt')\n",
    "\n",
    "y = to_categorical(y)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 11s 531us/step - loss: 0.4453 - acc: 0.7955\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 6s 301us/step - loss: 0.3064 - acc: 0.8670\n",
      "Test score: 0.2141753667\n",
      "Test accuracy: 0.9293\n"
     ]
    }
   ],
   "source": [
    "m = make_model(X, y, X, y)[1]\n",
    "pred = m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_pred(pred):\n",
    "    result = [1 if i[0] == 0 else 0 for i in np.round(pred)]\n",
    "    with open(\"result.txt\", \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\") \n",
    "        for i in range(1, len(result) + 1):\n",
    "            f.write(str(i) + \",\" + str(result[i-1]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_pred(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
